---
layout: single
title: Qwen2VL解析
categories:
  - AI
tags:
  - 网络模型
---

* content
{:toc}
  

## Vision部分

在`config.json`中vision部分的配置如下：

```json
"vision_config": {
    "depth": 32,
    "embed_dim": 1280,
    "mlp_ratio": 4,
    "num_heads": 16,
    "in_chans": 3,
    "hidden_size": 1536,
    "patch_size": 14,
    "spatial_merge_size": 2,
    "spatial_patch_size": 14,
    "temporal_patch_size": 2
  }
```

<!--more-->

### 图片预处理过程

预处理过程可以看`Qwen2VLImageProcessor`的实现

**第一步，Resize**

比如图片尺寸是`600x800`，先寻找接近28 (注：`merge_sizexpatch_size`)倍数的尺寸，得到`588x784`，确定这个像素量<= `max_pixels`。如果大于，则需要调整到`max_piexls`内；同理如下小于`min_piexls`也要调整。然后将图片Resize到`588x784`

源码如下：

``` python
def smart_resize(
    height: int, width: int, factor: int = 28, min_pixels: int = 56 * 56, max_pixels: int = 14 * 14 * 4 * 1280
):
    """Rescales the image so that the following conditions are met:

    1. Both dimensions (height and width) are divisible by 'factor'.

    2. The total number of pixels is within the range ['min_pixels', 'max_pixels'].

    3. The aspect ratio of the image is maintained as closely as possible.

    """
    if height < factor or width < factor:
        raise ValueError(f"height:{height} or width:{width} must be larger than factor:{factor}")
    elif max(height, width) / min(height, width) > 200:
        raise ValueError(
            f"absolute aspect ratio must be smaller than 200, got {max(height, width) / min(height, width)}"
        )
    h_bar = round(height / factor) * factor
    w_bar = round(width / factor) * factor
    if h_bar * w_bar > max_pixels:
        beta = math.sqrt((height * width) / max_pixels)
        h_bar = math.floor(height / beta / factor) * factor
        w_bar = math.floor(width / beta / factor) * factor
    elif h_bar * w_bar < min_pixels:
        beta = math.sqrt(min_pixels / (height * width))
        h_bar = math.ceil(height * beta / factor) * factor
        w_bar = math.ceil(width * beta / factor) * factor
    return h_bar, w_bar
```

**第二步，图片归一化**

将图片数值从u8转换成[-1,1]的float值。此时数据为`data = float [1, 3,  784, 588]`

**第三步，temporal处理**

batch维度叠加到`temporal_patch_size`的大小，此时数据为`data = float [2, 3, 784, 588]`

也就是这里`data[0] == data[1]`

**第四步，维度转换**

参数如下：

```text
grid_t = data.shape[0]//`temporal_patch_size` = 1
grid_h = 784 / patch_size = 56
grid_w = 588 / patch_size = 42
data = data.reshape(grid_t, temporal_patch_size, channel, grid_h//merge_size, merge_size, patch_size, grid_w//merge_size, merge_size, patch_size) = data[1, 2, 3, 28, 2, 14, 21,2,14]
```

转换过程如下：

```
data[2, 3, 784, 588] 
=>data[1, 2, 3, 28, 2, 14, 21, 2, 14]
=> transpose(0, 3, 6, 4, 7, 2, 1, 5, 8)
=> data[1, 28, 21, 2, 2, 3, 2, 14, 14]
=> reshape(grid_t x grid_h x grid_w, channel x temporal_patch_size x patch_size x patch_size)
=> data[2352, 1176]
```

**理解**

以上是预处理过程，进一步理解这个处理过程的涵义大致如下：

* `patch_size`：图片会被切分成`14x14`的网格
* `temporal_patch_size`: `Qwen2-VL`把视频当做1秒2帧图片处理，为了统一图片和视频，会把图片复制一份
* `grid_t/grid_h/grid_w`: 表示时间/高度/宽度三个维度的网格数
* `merge_size`: 从transpose过程可以看出`grid_h`和`grid_w` 做了`2x2`的融合处理
* `[2352, 1176]`: 最终的shape，可以理解成网络index与网格数据



### VIT

待续

